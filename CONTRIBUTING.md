# ğŸ¤ GuÃ­a de ContribuciÃ³n

## ğŸŒŸ Â¿CÃ³mo Contribuir?

1. **Fork y Clone**
   ```bash
   # Fork usando GitHub y luego:
   git clone https://github.com/TU_USUARIO/scrappy-doo.git
   cd scrappy-doo
   ```

2. **Crear Rama**
   ```bash
   # Crear rama para tu feature
   git checkout -b feature/nombre-descriptivo
   # o para un fix
   git checkout -b fix/nombre-descriptivo
   ```

3. **Desarrollar**
   - Escribe cÃ³digo limpio y mantenible
   - Sigue las convenciones de estilo
   - AÃ±ade pruebas para nuevas funcionalidades
   - Actualiza la documentaciÃ³n si es necesario

4. **Commit**
   ```bash
   git add .
   git commit -m "feat: descripciÃ³n corta del cambio"
   ```
   
   Tipos de commit:
   - `feat`: Nueva caracterÃ­stica
   - `fix`: CorrecciÃ³n de bug
   - `docs`: Cambios en documentaciÃ³n
   - `style`: Cambios de formato
   - `refactor`: RefactorizaciÃ³n de cÃ³digo
   - `test`: AÃ±adir o modificar pruebas
   - `chore`: Tareas de mantenimiento

5. **Push y Pull Request**
   ```bash
   git push origin feature/nombre-descriptivo
   ```
   Luego crea un Pull Request en GitHub.

## ğŸ“ Convenciones de CÃ³digo

### Estilo
- Usa 2 espacios para indentaciÃ³n
- Punto y coma al final de cada declaraciÃ³n
- Usa comillas simples para strings
- Nombra variables y funciones en camelCase
- Nombra clases en PascalCase
- Archivos en kebab-case.js

### Ejemplo
```javascript
class ProductScraper {
  constructor() {
    this.config = {
      timeout: 5000,
      retries: 3
    };
  }

  async scrapeProduct(url) {
    try {
      // ImplementaciÃ³n
    } catch (error) {
      logger.error('Error:', error);
      throw error;
    }
  }
}
```

### DocumentaciÃ³n
- Documenta todas las funciones pÃºblicas
- Usa JSDoc para documentaciÃ³n de cÃ³digo
- MantÃ©n el README actualizado
- AÃ±ade ejemplos de uso cuando sea posible

## ğŸ§ª Pruebas

### Ejecutar Pruebas
```bash
# Todas las pruebas
npm test

# Pruebas especÃ­ficas
npm test -- src/tests/scraper-tests.js
```

### Escribir Pruebas
```javascript
describe('ProductScraper', () => {
  it('debe extraer correctamente el precio', async () => {
    const scraper = new ProductScraper();
    const result = await scraper.scrapeProduct(testUrl);
    expect(result.price).toBeDefined();
  });
});
```

## ğŸ” RevisiÃ³n de CÃ³digo

Tu PR serÃ¡ revisado considerando:
- âœ¨ Calidad del cÃ³digo
- ğŸ§ª Cobertura de pruebas
- ğŸ“ DocumentaciÃ³n
- ğŸ¯ Impacto en el rendimiento
- ğŸ”’ Seguridad

## âš ï¸ Buenas PrÃ¡cticas

### Scraping
- Implementa delays entre requests
- Usa User-Agents aleatorios
- Respeta robots.txt
- Implementa manejo de errores robusto
- Usa proxies cuando sea necesario

### Seguridad
- No comitees credenciales
- Usa variables de entorno
- Valida input de usuario
- Implementa rate limiting
- Maneja errores de forma segura

## ğŸ“‹ Checklist PR

- [ ] CÃ³digo sigue las convenciones de estilo
- [ ] Pruebas aÃ±adidas/actualizadas
- [ ] DocumentaciÃ³n actualizada
- [ ] Cambios probados localmente
- [ ] No hay credenciales expuestas
- [ ] Rama actualizada con main

## ğŸ‰ Â¡Gracias por Contribuir!

Tu contribuciÃ³n hace que ScrappyDoo sea mejor para todos. Si tienes dudas, no dudes en abrir un issue o preguntar en las discusiones. 